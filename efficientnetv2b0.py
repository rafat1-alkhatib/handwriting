# -*- coding: utf-8 -*-
"""EfficientNetV2B0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hnxBQ84KDLh9RqjDMQv8DAlOaG7Yr7CF
"""

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf     ##tensorflow-gpu
import cv2                  ##opencv-python
import os
import matplotlib.pyplot as plt  ## matplotlib
import numpy as np
from google.colab.patches import cv2_imshow
from sklearn.model_selection import train_test_split

device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
    print('GPU device not found. Make sure you have enabled the GPU runtime.')
else:
    print('GPU device found:', device_name)

import cv2
import numpy as np

def resize_with_padding(image, target_size, padding_color=(0, 0, 0)):
    try:
        height, width = image.shape[:2]
        target_height, target_width = target_size

        # Calculate the aspect ratio of the original image
        aspect_ratio = width / height

        # Calculate the target aspect ratio
        target_aspect_ratio = target_width / target_height

        # Calculate the new size with padding
        if target_aspect_ratio > aspect_ratio:
            new_width = int(target_height * aspect_ratio)
            new_height = target_height
            pad_left = (target_width - new_width) // 2
            pad_right = target_width - new_width - pad_left
            pad_top = 0
            pad_bottom = 0
        else:
            new_width = target_width
            new_height = int(target_width / aspect_ratio)
            pad_left = 0
            pad_right = 0
            pad_top = (target_height - new_height) // 2
            pad_bottom = target_height - new_height - pad_top

        # Resize the image while maintaining the aspect ratio
        resized_image = cv2.resize(image, (new_width, new_height))

        # Create a new image with the target size and fill it with padding color
        padded_image = np.full((target_height, target_width, 3), padding_color, dtype=np.uint8)
        padded_image[pad_top:pad_top+new_height, pad_left:pad_left+new_width] = resized_image

        return padded_image

    except Exception as e:
        print("An error occurred during image resizing:", str(e))
        return None

train_data=r'/content/drive/MyDrive/2 ba'

Classes = ["2.1","2.2","2.3","2.4"]

print(".........1_Step...............")
for category in Classes :
    path=os.path.join(train_data,category)
    for img in os.listdir(path):
       img_array=cv2.imread(os.path.join(path,img))
       backtorgb = cv2.cvtColor(img_array,cv2.COLOR_BGR2RGB)
       plt.imshow(cv2.cvtColor(img_array,cv2.COLOR_BGR2RGB))
       plt.show()
       break
    break
print(".........2_Step...............")
print("Resize_image")
img_size= 224 # ImageNet=>224*224
new_array = resize_with_padding(img_array, (224, 224), padding_color=(255, 255, 255))  # Resize the image with padding and set padding color to white
cv2_imshow(new_array)
cv2.waitKey(0)
cv2.destroyAllWindows()

print("new_array")
new_array.shape

print("old_array")
img_array.shape

print(".........3_Step...............")
print("read all the images and convertin them to array")
training_Data =[]  ## data
def create_training_Data():
      for category in Classes:
          path=os.path.join(train_data,category)
          class_num= Classes.index(category)   ## 0 1 ##lable
          for img in os.listdir(path):
              try:
                  img_array=cv2.imread(os.path.join(path,img))
                  new_array=cv2.resize(img_array,(img_size,img_size))
                  training_Data.append([new_array,class_num])
              except Exception as e:
                  pass
print("training_Data")
create_training_Data()
print(len(training_Data))

print(".........3_Step...............")
temp=np.array(training_Data)
temp.shape
import random
random.shuffle(training_Data)
X=[]   ##data/feature
Y=[]   ## label
for features,label in training_Data:
    X.append(features)
    Y.append(label)
print("converting it to 4 dimenstion")
X=np.array(X).reshape(-1,img_size,img_size,3)  ## converting it to 4 dimenstion
X.shape   ##output: (un data ,224,224,3)

print(".........4_Step...............")
print("normalize the data")
X=X/255.0;  #we ara normalizrd it
Y=np.array(Y)
Y.shape
X.shape

X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=12)
print(X_train.shape)

print(".........1_Step...............")
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.applications import ResNet50
print(".........2_Step...............")
print("per-trained Model")
model= tf.keras.applications.EfficientNetV2B0()
#model = ResNet50(include_top=False, weights='imagenet', input_shape=(32, 32, 3))
#model.summary()
print(".........3_Step...............")
print("Transfer Learning -Tuning ,weights will start from last check point")
base_input = model.layers[0].input
base_output=model.layers[-2].output
base_input
base_output

print(".........4_Step...............")
print("New_model")
final_output=layers.Dense(128)(base_output)   ##adding new layer , after the output  of global pooling layer
#final_output=layers.Dropout(0.4)(final_output)
final_output=layers.Activation ('relu')(final_output)  ##activation function
final_output=layers.Dense(64)(final_output)
#final_output=layers.Dropout(0.4)(final_output)
final_output=layers.Activation('relu')(final_output)
final_output=layers.Dense(4,activation='softmax')(final_output)  ## my classes are 07
final_output

print(".........5_Step...............")
new_model = keras.Model(inputs=base_input ,outputs=final_output)
#new_model.summary()

print(".........7_Step...............")
new_model.compile(loss="sparse_categorical_crossentropy",optimizer="adam",run_eagerly=True,metrics= ["accuracy"])

import time
start_time= time.time()
history=new_model.fit(X_train,y_train,epochs=20)
ent_time=time.time()

time=ent_time-start_time
print(f" Time: {time} s")

new_model.save('model_res04.h5')
new_model=tf.keras.models.load_model('model_res04.h5')

loss, accuracy=new_model.evaluate(X_test,y_test)
print("accuracy=",accuracy)

loss, accuracy=new_model.evaluate(X_train,y_train)
print("accuracy=",accuracy)

SIZE=256
new_model=tf.keras.models.load_model('/content/model_res04.h5')

# Commented out IPython magic to ensure Python compatibility.
print(".........8_Step...............")
print("list all data in history")
import matplotlib.pyplot as plt
from tensorflow.python.lib.io import file_io
# %matplotlib inline
import keras
from keras import backend as K
from keras.callbacks import ModelCheckpoint, EarlyStopping
from keras.preprocessing.image import ImageDataGenerator
from keras.utils import plot_model
from sklearn.metrics import *
import skimage
from skimage.transform import rescale, resize
import pydot
print(".........9_Step...............")
# list all data in history",
print(history.history.keys())
# summarize history for accuracy
plt.plot(history.history['accuracy'])
#plt.plot(history.history['val_acc'])
plt.title('new_model resnet accuracy')
plt.ylabel('accuracy(%)')
plt.xlabel('epoch')
plt.legend(['train', 'dev'], loc='upper left')
plt.show()
 #summarize history for loss
plt.plot(history.history['loss'])
#plt.plot(history.history['val_loss'])
plt.title('new_model loss(%)')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'dev'], loc='upper left')
plt.show()

import tensorflow as tf
from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input, decode_predictions
from tensorflow.keras.preprocessing import image
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Model
# Load and preprocess the image
img_path = '/content/ba.png'
img = image.load_img(img_path, target_size=(224, 224))
x = image.img_to_array(img)
x = preprocess_input(x)
x = tf.expand_dims(x, axis=0)

# Perform image prediction
new_x = resize_with_padding(x, (256, 256), padding_color=(255, 255, 255))  # Resize the image with padding and set padding color to white
new_x = preprocess_input(new_x)
new_x = tf.expand_dims(x, axis=0)
preds = new_model.predict(x)
print(preds)

#print(".........10_Step...............")
#print(".........Test dataset ...............")
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

import tensorflow as tf
from tensorflow.python.lib.io import file_io

import keras
from keras.preprocessing.image import ImageDataGenerator

from sklearn.metrics import confusion_matrix
from seaborn import heatmap

emotions = {0:'Ioslated_ba', 1:'ba_with_first', 2:'ba_with_middel', 3:'ba_with_end'}

y_pred = new_model.predict_generator(X_test).argmax(axis=1)
y_true = y_test

cmat_df_test=pd.DataFrame(
  confusion_matrix(y_true, y_pred, normalize='true').round(2),
  index=emotions.values(),
  columns=emotions.values()
  )
plt.figure(figsize=(5,5))
heatmap(cmat_df_test,annot=True,cmap=plt.cm.Blues)
plt.tight_layout()
plt.title('Confusion Matrix on Private Test Set')
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.show()
print(" Finding Accuracy, precision and recall")
# Finding precision and recall
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy   :", accuracy)
precision = precision_score(y_test, y_pred,average="weighted")
print("Precision :", precision)
recall = recall_score(y_test, y_pred,average="weighted")
print("Recall    :", recall)
F1_score = f1_score(y_test, y_pred,average="weighted")
print("F1-score  :", F1_score)

# #print(".........Train dataset ...............")
# import matplotlib.pyplot as plt
# import pandas as pd
# import numpy as np

# import tensorflow as tf
# from tensorflow.python.lib.io import file_io

# import keras
# from keras.preprocessing.image import ImageDataGenerator

# from sklearn.metrics import confusion_matrix
# from seaborn import heatmap

# emotions = {0:'Ioslated_ba', 1:'ba_with_first', 2:'ba_with_middel', 3:'ba_with_end'}

# y_pred = new_model.predict_generator(X_train).argmax(axis=1)
# y_true = y_train

# cmat_df_test=pd.DataFrame(
#   confusion_matrix(y_true, y_pred, normalize='true').round(2),
#   index=emotions.values(),
#   columns=emotions.values()
#   )
# plt.figure(figsize=(5,5))
# heatmap(cmat_df_test,annot=True,cmap=plt.cm.Blues)
# plt.tight_layout()
# plt.title('Confusion Matrix on Private Train Set')
# plt.ylabel('True label')
# plt.xlabel('Predicted label')
# plt.show()
# print(" Finding Accuracy, precision and recall")
# # Finding precision and recall
# accuracy = accuracy_score(y_train, y_pred)
# print("Accuracy   :", accuracy)
# precision = precision_score(y_train, y_pred,average="weighted")
# print("Precision :", precision)
# recall = recall_score(y_train, y_pred,average="weighted")
# print("Recall    :", recall)
# F1_score = f1_score(y_train, y_pred,average="weighted")
# print("F1-score  :", F1_score)

print(".........6_Step...............")
print("Loaded without classifier/ fully connected layers")
from keras.applications.vgg16 import VGG16
SIZE=256
model = VGG16(weights='imagenet',include_top= False , input_shape=(SIZE,SIZE,3))
print(".........7_Step...............")
#Make loaded layers as non-trainable. This is important as we want to work with pre-trained weights
for layer in model.layers:
	layer.trainable = False
model.summary()  #Trainable parameters will be 0

SIZE=256
new_model=tf.keras.models.load_model('/content/model_res04.h5')

for layer in new_model.layers:
	layer.trainable = False

print(".........8_Step...............")
#Now, let us use features from convolutional network for RF
feature_ext= new_model.predict(X_train)
X_features = feature_ext.reshape(feature_ext.shape[0], -1)

print(feature_ext.shape)

print("feature for 0.2 ResNet50\n",
      feature_ext[0])

imge_features= (feature_ext[0]*255).astype(np.uint8)

pip install PIT

from PIL import Image
image=Image.fromarray(imge_features)
image.save("imge_features.png")
np.save("feature_ext.npy",feature_ext)